{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 网络结构的可视化\n",
    "## 准备网络和数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.utils as vutils\n",
    "from torch.optim import SGD\n",
    "import torch.utils.data as Data\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = torchvision.datasets.MNIST(\n",
    "    root=\"./data/MNIST\", ## 数据的路径\n",
    "    train=True,     ## 只使用训练数据集\n",
    "    ## 将数据转化为torch使用的张量，取值范围是[0,1]\n",
    "    transform=torchvision.transforms.ToTensor(),\n",
    "    download=False  ## 因为数据已经过，所以这里不再下载\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = Data.DataLoader(\n",
    "    dataset=train_data,\n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    "    num_workers=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "for step, (b_x,b_y) in enumerate(train_loader):\n",
    "    if step > 0:\n",
    "        break\n",
    "\n",
    "print(b_x.shape)\n",
    "print(b_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = torchvision.datasets.MNIST(\n",
    "    root = \"./data/MNIST\",\n",
    "    train=False,\n",
    "    download=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_data_x.shape: torch.Size([10000, 1, 28, 28])\n",
      "test_data_y.shape: torch.Size([10000])\n"
     ]
    }
   ],
   "source": [
    "test_data_x = test_data.data.type(torch.FloatTensor) / 255.0\n",
    "test_data_x = torch.unsqueeze(test_data_x, dim=1)\n",
    "test_data_y = test_data.targets\n",
    "print(\"test_data_x.shape:\",test_data_x.shape)\n",
    "print(\"test_data_y.shape:\",test_data_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 搭建一个卷积神经网络\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(ConvNet, self).__init__()\n",
    "        ## 定义第一个卷积层\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=1,\n",
    "                out_channels=16,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=1,\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.AvgPool2d(\n",
    "                kernel_size=2,\n",
    "                stride=2,\n",
    "            ),\n",
    "        )\n",
    "        ## 定义第二个卷积层\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(16,32,3,1,1),\n",
    "            nn.ReLU(),              ## 激活函数\n",
    "            nn.MaxPool2d(2,2)       ## 最大池化层\n",
    "        )\n",
    "\n",
    "        ## 定义全连接层\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(\n",
    "                in_features=32*7*7,\n",
    "                out_features=128,\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128,64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.out = nn.Linear(64, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        output = self.out(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvNet(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=1568, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (out): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "## 输出网络结构\n",
    "MyConvnet = ConvNet()\n",
    "print(MyConvnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "_jit_pass_onnx_unpack_quantized_weights(): incompatible function arguments. The following argument types are supported:\n    1. (arg0: torch::jit::Graph, arg1: Dict[str, IValue], arg2: bool) -> Dict[str, IValue]\n\nInvoked with: graph(%input.1 : Float(1, 1, 28, 28, strides=[784, 784, 28, 1], requires_grad=0, device=cpu),\n      %1 : Float(16, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=1, device=cpu),\n      %2 : Float(16, strides=[1], requires_grad=1, device=cpu),\n      %3 : Float(32, 16, 3, 3, strides=[144, 9, 3, 1], requires_grad=1, device=cpu),\n      %4 : Float(32, strides=[1], requires_grad=1, device=cpu),\n      %5 : Float(128, 1568, strides=[1568, 1], requires_grad=1, device=cpu),\n      %6 : Float(128, strides=[1], requires_grad=1, device=cpu),\n      %7 : Float(64, 128, strides=[128, 1], requires_grad=1, device=cpu),\n      %8 : Float(64, strides=[1], requires_grad=1, device=cpu),\n      %9 : Float(10, 64, strides=[64, 1], requires_grad=1, device=cpu),\n      %10 : Float(10, strides=[1], requires_grad=1, device=cpu)):\n  %112 : int[] = prim::Constant[value=[1, 1]]()\n  %113 : int[] = prim::Constant[value=[1, 1]]()\n  %114 : int[] = prim::Constant[value=[1, 1]]()\n  %42 : bool = prim::Constant[value=0]() # c:\\software\\lib\\site-packages\\torch\\nn\\modules\\conv.py:453:0\n  %115 : int[] = prim::Constant[value=[0, 0]]()\n  %46 : int = prim::Constant[value=1]() # c:\\software\\lib\\site-packages\\torch\\nn\\modules\\conv.py:453:0\n  %47 : bool = prim::Constant[value=0]() # c:\\software\\lib\\site-packages\\torch\\nn\\modules\\conv.py:453:0\n  %48 : bool = prim::Constant[value=0]() # c:\\software\\lib\\site-packages\\torch\\nn\\modules\\conv.py:453:0\n  %49 : bool = prim::Constant[value=1]() # c:\\software\\lib\\site-packages\\torch\\nn\\modules\\conv.py:453:0\n  %50 : bool = prim::Constant[value=1]() # c:\\software\\lib\\site-packages\\torch\\nn\\modules\\conv.py:453:0\n  %input.3 : Float(1, 16, 28, 28, strides=[12544, 784, 28, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.1, %1, %2, %112, %113, %114, %42, %115, %46, %47, %48, %49, %50) # c:\\software\\lib\\site-packages\\torch\\nn\\modules\\conv.py:453:0\n  %52 : Float(1, 16, 28, 28, strides=[12544, 784, 28, 1], requires_grad=1, device=cpu) = aten::relu(%input.3) # c:\\software\\lib\\site-packages\\torch\\nn\\functional.py:1457:0\n  %116 : int[] = prim::Constant[value=[2, 2]]()\n  %117 : int[] = prim::Constant[value=[2, 2]]()\n  %118 : int[] = prim::Constant[value=[0, 0]]()\n  %62 : bool = prim::Constant[value=0]() # c:\\software\\lib\\site-packages\\torch\\nn\\modules\\pooling.py:622:0\n  %63 : bool = prim::Constant[value=1]() # c:\\software\\lib\\site-packages\\torch\\nn\\modules\\pooling.py:622:0\n  %64 : NoneType = prim::Constant()\n  %input.5 : Float(1, 16, 14, 14, strides=[3136, 196, 14, 1], requires_grad=1, device=cpu) = aten::avg_pool2d(%52, %116, %117, %118, %62, %63, %64) # c:\\software\\lib\\site-packages\\torch\\nn\\modules\\pooling.py:622:0\n  %119 : int[] = prim::Constant[value=[1, 1]]()\n  %120 : int[] = prim::Constant[value=[1, 1]]()\n  %121 : int[] = prim::Constant[value=[1, 1]]()\n  %75 : bool = prim::Constant[value=0]() # c:\\software\\lib\\site-packages\\torch\\nn\\modules\\conv.py:453:0\n  %122 : int[] = prim::Constant[value=[0, 0]]()\n  %79 : int = prim::Constant[value=1]() # c:\\software\\lib\\site-packages\\torch\\nn\\modules\\conv.py:453:0\n  %80 : bool = prim::Constant[value=0]() # c:\\software\\lib\\site-packages\\torch\\nn\\modules\\conv.py:453:0\n  %81 : bool = prim::Constant[value=0]() # c:\\software\\lib\\site-packages\\torch\\nn\\modules\\conv.py:453:0\n  %82 : bool = prim::Constant[value=1]() # c:\\software\\lib\\site-packages\\torch\\nn\\modules\\conv.py:453:0\n  %83 : bool = prim::Constant[value=1]() # c:\\software\\lib\\site-packages\\torch\\nn\\modules\\conv.py:453:0\n  %input.7 : Float(1, 32, 14, 14, strides=[6272, 196, 14, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.5, %3, %4, %119, %120, %121, %75, %122, %79, %80, %81, %82, %83) # c:\\software\\lib\\site-packages\\torch\\nn\\modules\\conv.py:453:0\n  %85 : Float(1, 32, 14, 14, strides=[6272, 196, 14, 1], requires_grad=1, device=cpu) = aten::relu(%input.7) # c:\\software\\lib\\site-packages\\torch\\nn\\functional.py:1457:0\n  %123 : int[] = prim::Constant[value=[2, 2]]()\n  %124 : int[] = prim::Constant[value=[2, 2]]()\n  %125 : int[] = prim::Constant[value=[0, 0]]()\n  %126 : int[] = prim::Constant[value=[1, 1]]()\n  %98 : bool = prim::Constant[value=0]() # c:\\software\\lib\\site-packages\\torch\\nn\\functional.py:782:0\n  %99 : Float(1, 32, 7, 7, strides=[1568, 49, 7, 1], requires_grad=1, device=cpu) = aten::max_pool2d(%85, %123, %124, %125, %126, %98) # c:\\software\\lib\\site-packages\\torch\\nn\\functional.py:782:0\n  %100 : int = prim::Constant[value=0]() # C:\\Users\\edgar\\AppData\\Local\\Temp\\ipykernel_22348\\857547553.py:43:0\n  %101 : int = aten::size(%99, %100) # C:\\Users\\edgar\\AppData\\Local\\Temp\\ipykernel_22348\\857547553.py:43:0\n  %104 : int = prim::Constant[value=-1]() # C:\\Users\\edgar\\AppData\\Local\\Temp\\ipykernel_22348\\857547553.py:43:0\n  %105 : int[] = prim::ListConstruct(%101, %104)\n  %106 : Float(1, 1568, strides=[1568, 1], requires_grad=1, device=cpu) = aten::view(%99, %105) # C:\\Users\\edgar\\AppData\\Local\\Temp\\ipykernel_22348\\857547553.py:43:0\n  %input.9 : Float(1, 128, strides=[128, 1], requires_grad=1, device=cpu) = aten::linear(%106, %5, %6) # c:\\software\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114:0\n  %108 : Float(1, 128, strides=[128, 1], requires_grad=1, device=cpu) = aten::relu(%input.9) # c:\\software\\lib\\site-packages\\torch\\nn\\functional.py:1457:0\n  %input : Float(1, 64, strides=[64, 1], requires_grad=1, device=cpu) = aten::linear(%108, %7, %8) # c:\\software\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114:0\n  %110 : Float(1, 64, strides=[64, 1], requires_grad=1, device=cpu) = aten::relu(%input) # c:\\software\\lib\\site-packages\\torch\\nn\\functional.py:1457:0\n  %111 : Float(1, 10, strides=[10, 1], requires_grad=1, device=cpu) = aten::linear(%110, %9, %10) # c:\\software\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114:0\n  return (%111)\n, None, False",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\learnPytorch\\lesson4.ipynb Cell 10'\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/learnPytorch/lesson4.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mhiddenlayer\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mhl\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/learnPytorch/lesson4.ipynb#X12sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m## 可视化神经网络\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/learnPytorch/lesson4.ipynb#X12sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m hl_graph \u001b[39m=\u001b[39m hl\u001b[39m.\u001b[39;49mbuild_graph(MyConvnet, torch\u001b[39m.\u001b[39;49mzeros([\u001b[39m1\u001b[39;49m,\u001b[39m1\u001b[39;49m,\u001b[39m28\u001b[39;49m,\u001b[39m28\u001b[39;49m]))\n",
      "File \u001b[1;32mc:\\software\\lib\\site-packages\\hiddenlayer\\graph.py:143\u001b[0m, in \u001b[0;36mbuild_graph\u001b[1;34m(model, args, input_names, transforms, framework_transforms)\u001b[0m\n\u001b[0;32m    141\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mpytorch_builder\u001b[39;00m \u001b[39mimport\u001b[39;00m import_graph, FRAMEWORK_TRANSFORMS\n\u001b[0;32m    142\u001b[0m     \u001b[39massert\u001b[39;00m args \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mArgument args must be provided for Pytorch models.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m--> 143\u001b[0m     import_graph(g, model, args)\n\u001b[0;32m    144\u001b[0m \u001b[39melif\u001b[39;00m framework \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtensorflow\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    145\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mtf_builder\u001b[39;00m \u001b[39mimport\u001b[39;00m import_graph, FRAMEWORK_TRANSFORMS\n",
      "File \u001b[1;32mc:\\software\\lib\\site-packages\\hiddenlayer\\pytorch_builder.py:71\u001b[0m, in \u001b[0;36mimport_graph\u001b[1;34m(hl_graph, model, args, input_names, verbose)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mimport_graph\u001b[39m(hl_graph, model, args, input_names\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, verbose\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m     67\u001b[0m     \u001b[39m# TODO: add input names to graph\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \n\u001b[0;32m     69\u001b[0m     \u001b[39m# Run the Pytorch graph to get a trace and generate a graph from it\u001b[39;00m\n\u001b[0;32m     70\u001b[0m     trace, out \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mjit\u001b[39m.\u001b[39m_get_trace_graph(model, args)\n\u001b[1;32m---> 71\u001b[0m     torch_graph \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49monnx\u001b[39m.\u001b[39;49m_optimize_trace(trace, torch\u001b[39m.\u001b[39;49monnx\u001b[39m.\u001b[39;49mOperatorExportTypes\u001b[39m.\u001b[39;49mONNX)\n\u001b[0;32m     73\u001b[0m     \u001b[39m# Dump list of nodes (DEBUG only)\u001b[39;00m\n\u001b[0;32m     74\u001b[0m     \u001b[39mif\u001b[39;00m verbose:\n",
      "File \u001b[1;32mc:\\software\\lib\\site-packages\\torch\\onnx\\__init__.py:394\u001b[0m, in \u001b[0;36m_optimize_trace\u001b[1;34m(graph, operator_export_type)\u001b[0m\n\u001b[0;32m    391\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_optimize_trace\u001b[39m(graph, operator_export_type):\n\u001b[0;32m    392\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39monnx\u001b[39;00m \u001b[39mimport\u001b[39;00m utils\n\u001b[1;32m--> 394\u001b[0m     \u001b[39mreturn\u001b[39;00m utils\u001b[39m.\u001b[39;49m_optimize_graph(graph, operator_export_type)\n",
      "File \u001b[1;32mc:\\software\\lib\\site-packages\\torch\\onnx\\utils.py:277\u001b[0m, in \u001b[0;36m_optimize_graph\u001b[1;34m(graph, operator_export_type, _disable_torch_constant_prop, fixed_batch_size, params_dict, dynamic_axes, input_names, module)\u001b[0m\n\u001b[0;32m    275\u001b[0m symbolic_helper\u001b[39m.\u001b[39m_quantized_ops\u001b[39m.\u001b[39mclear()\n\u001b[0;32m    276\u001b[0m \u001b[39m# Unpack quantized weights for conv and linear ops and insert into graph.\u001b[39;00m\n\u001b[1;32m--> 277\u001b[0m _C\u001b[39m.\u001b[39;49m_jit_pass_onnx_unpack_quantized_weights(\n\u001b[0;32m    278\u001b[0m     graph, params_dict, symbolic_helper\u001b[39m.\u001b[39;49mis_caffe2_aten_fallback()\n\u001b[0;32m    279\u001b[0m )\n\u001b[0;32m    280\u001b[0m \u001b[39mif\u001b[39;00m symbolic_helper\u001b[39m.\u001b[39mis_caffe2_aten_fallback():\n\u001b[0;32m    281\u001b[0m     \u001b[39m# Insert permutes before and after each conv op to ensure correct order.\u001b[39;00m\n\u001b[0;32m    282\u001b[0m     _C\u001b[39m.\u001b[39m_jit_pass_onnx_quantization_insert_permutes(graph, params_dict)\n",
      "\u001b[1;31mTypeError\u001b[0m: _jit_pass_onnx_unpack_quantized_weights(): incompatible function arguments. The following argument types are supported:\n    1. (arg0: torch::jit::Graph, arg1: Dict[str, IValue], arg2: bool) -> Dict[str, IValue]\n\nInvoked with: graph(%input.1 : Float(1, 1, 28, 28, strides=[784, 784, 28, 1], requires_grad=0, device=cpu),\n      %1 : Float(16, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=1, device=cpu),\n      %2 : Float(16, strides=[1], requires_grad=1, device=cpu),\n      %3 : Float(32, 16, 3, 3, strides=[144, 9, 3, 1], requires_grad=1, device=cpu),\n      %4 : Float(32, strides=[1], requires_grad=1, device=cpu),\n      %5 : Float(128, 1568, strides=[1568, 1], requires_grad=1, device=cpu),\n      %6 : Float(128, strides=[1], requires_grad=1, device=cpu),\n      %7 : Float(64, 128, strides=[128, 1], requires_grad=1, device=cpu),\n      %8 : Float(64, strides=[1], requires_grad=1, device=cpu),\n      %9 : Float(10, 64, strides=[64, 1], requires_grad=1, device=cpu),\n      %10 : Float(10, strides=[1], requires_grad=1, device=cpu)):\n  %112 : int[] = prim::Constant[value=[1, 1]]()\n  %113 : int[] = prim::Constant[value=[1, 1]]()\n  %114 : int[] = prim::Constant[value=[1, 1]]()\n  %42 : bool = prim::Constant[value=0]() # c:\\software\\lib\\site-packages\\torch\\nn\\modules\\conv.py:453:0\n  %115 : int[] = prim::Constant[value=[0, 0]]()\n  %46 : int = prim::Constant[value=1]() # c:\\software\\lib\\site-packages\\torch\\nn\\modules\\conv.py:453:0\n  %47 : bool = prim::Constant[value=0]() # c:\\software\\lib\\site-packages\\torch\\nn\\modules\\conv.py:453:0\n  %48 : bool = prim::Constant[value=0]() # c:\\software\\lib\\site-packages\\torch\\nn\\modules\\conv.py:453:0\n  %49 : bool = prim::Constant[value=1]() # c:\\software\\lib\\site-packages\\torch\\nn\\modules\\conv.py:453:0\n  %50 : bool = prim::Constant[value=1]() # c:\\software\\lib\\site-packages\\torch\\nn\\modules\\conv.py:453:0\n  %input.3 : Float(1, 16, 28, 28, strides=[12544, 784, 28, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.1, %1, %2, %112, %113, %114, %42, %115, %46, %47, %48, %49, %50) # c:\\software\\lib\\site-packages\\torch\\nn\\modules\\conv.py:453:0\n  %52 : Float(1, 16, 28, 28, strides=[12544, 784, 28, 1], requires_grad=1, device=cpu) = aten::relu(%input.3) # c:\\software\\lib\\site-packages\\torch\\nn\\functional.py:1457:0\n  %116 : int[] = prim::Constant[value=[2, 2]]()\n  %117 : int[] = prim::Constant[value=[2, 2]]()\n  %118 : int[] = prim::Constant[value=[0, 0]]()\n  %62 : bool = prim::Constant[value=0]() # c:\\software\\lib\\site-packages\\torch\\nn\\modules\\pooling.py:622:0\n  %63 : bool = prim::Constant[value=1]() # c:\\software\\lib\\site-packages\\torch\\nn\\modules\\pooling.py:622:0\n  %64 : NoneType = prim::Constant()\n  %input.5 : Float(1, 16, 14, 14, strides=[3136, 196, 14, 1], requires_grad=1, device=cpu) = aten::avg_pool2d(%52, %116, %117, %118, %62, %63, %64) # c:\\software\\lib\\site-packages\\torch\\nn\\modules\\pooling.py:622:0\n  %119 : int[] = prim::Constant[value=[1, 1]]()\n  %120 : int[] = prim::Constant[value=[1, 1]]()\n  %121 : int[] = prim::Constant[value=[1, 1]]()\n  %75 : bool = prim::Constant[value=0]() # c:\\software\\lib\\site-packages\\torch\\nn\\modules\\conv.py:453:0\n  %122 : int[] = prim::Constant[value=[0, 0]]()\n  %79 : int = prim::Constant[value=1]() # c:\\software\\lib\\site-packages\\torch\\nn\\modules\\conv.py:453:0\n  %80 : bool = prim::Constant[value=0]() # c:\\software\\lib\\site-packages\\torch\\nn\\modules\\conv.py:453:0\n  %81 : bool = prim::Constant[value=0]() # c:\\software\\lib\\site-packages\\torch\\nn\\modules\\conv.py:453:0\n  %82 : bool = prim::Constant[value=1]() # c:\\software\\lib\\site-packages\\torch\\nn\\modules\\conv.py:453:0\n  %83 : bool = prim::Constant[value=1]() # c:\\software\\lib\\site-packages\\torch\\nn\\modules\\conv.py:453:0\n  %input.7 : Float(1, 32, 14, 14, strides=[6272, 196, 14, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.5, %3, %4, %119, %120, %121, %75, %122, %79, %80, %81, %82, %83) # c:\\software\\lib\\site-packages\\torch\\nn\\modules\\conv.py:453:0\n  %85 : Float(1, 32, 14, 14, strides=[6272, 196, 14, 1], requires_grad=1, device=cpu) = aten::relu(%input.7) # c:\\software\\lib\\site-packages\\torch\\nn\\functional.py:1457:0\n  %123 : int[] = prim::Constant[value=[2, 2]]()\n  %124 : int[] = prim::Constant[value=[2, 2]]()\n  %125 : int[] = prim::Constant[value=[0, 0]]()\n  %126 : int[] = prim::Constant[value=[1, 1]]()\n  %98 : bool = prim::Constant[value=0]() # c:\\software\\lib\\site-packages\\torch\\nn\\functional.py:782:0\n  %99 : Float(1, 32, 7, 7, strides=[1568, 49, 7, 1], requires_grad=1, device=cpu) = aten::max_pool2d(%85, %123, %124, %125, %126, %98) # c:\\software\\lib\\site-packages\\torch\\nn\\functional.py:782:0\n  %100 : int = prim::Constant[value=0]() # C:\\Users\\edgar\\AppData\\Local\\Temp\\ipykernel_22348\\857547553.py:43:0\n  %101 : int = aten::size(%99, %100) # C:\\Users\\edgar\\AppData\\Local\\Temp\\ipykernel_22348\\857547553.py:43:0\n  %104 : int = prim::Constant[value=-1]() # C:\\Users\\edgar\\AppData\\Local\\Temp\\ipykernel_22348\\857547553.py:43:0\n  %105 : int[] = prim::ListConstruct(%101, %104)\n  %106 : Float(1, 1568, strides=[1568, 1], requires_grad=1, device=cpu) = aten::view(%99, %105) # C:\\Users\\edgar\\AppData\\Local\\Temp\\ipykernel_22348\\857547553.py:43:0\n  %input.9 : Float(1, 128, strides=[128, 1], requires_grad=1, device=cpu) = aten::linear(%106, %5, %6) # c:\\software\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114:0\n  %108 : Float(1, 128, strides=[128, 1], requires_grad=1, device=cpu) = aten::relu(%input.9) # c:\\software\\lib\\site-packages\\torch\\nn\\functional.py:1457:0\n  %input : Float(1, 64, strides=[64, 1], requires_grad=1, device=cpu) = aten::linear(%108, %7, %8) # c:\\software\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114:0\n  %110 : Float(1, 64, strides=[64, 1], requires_grad=1, device=cpu) = aten::relu(%input) # c:\\software\\lib\\site-packages\\torch\\nn\\functional.py:1457:0\n  %111 : Float(1, 10, strides=[10, 1], requires_grad=1, device=cpu) = aten::linear(%110, %9, %10) # c:\\software\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114:0\n  return (%111)\n, None, False"
     ]
    }
   ],
   "source": [
    "import hiddenlayer as hl\n",
    "## 可视化神经网络\n",
    "hl_graph = hl.build_graph(MyConvnet, torch.zeros([1,1,28,28]))\n",
    "# hl_graph.theme = hl.graph.THEMES[\"blue\"].copy()\n",
    "## 可视化的网络保存为图片\n",
    "# hl_graph.save(\"./data/lesson4_hiddenlay.png\", format=\"png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ExecutableNotFound",
     "evalue": "failed to execute WindowsPath('dot'), make sure the Graphviz executables are on your systems' PATH",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32mc:\\software\\lib\\site-packages\\graphviz\\backend\\execute.py:81\u001b[0m, in \u001b[0;36mrun_check\u001b[1;34m(cmd, input_lines, encoding, quiet, **kwargs)\u001b[0m\n\u001b[0;32m     80\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 81\u001b[0m         proc \u001b[39m=\u001b[39m subprocess\u001b[39m.\u001b[39;49mrun(cmd, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     82\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\software\\lib\\subprocess.py:489\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[0;32m    487\u001b[0m     kwargs[\u001b[39m'\u001b[39m\u001b[39mstderr\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m PIPE\n\u001b[1;32m--> 489\u001b[0m \u001b[39mwith\u001b[39;00m Popen(\u001b[39m*\u001b[39;49mpopenargs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs) \u001b[39mas\u001b[39;00m process:\n\u001b[0;32m    490\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\software\\lib\\subprocess.py:854\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors, text)\u001b[0m\n\u001b[0;32m    851\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr \u001b[39m=\u001b[39m io\u001b[39m.\u001b[39mTextIOWrapper(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr,\n\u001b[0;32m    852\u001b[0m                     encoding\u001b[39m=\u001b[39mencoding, errors\u001b[39m=\u001b[39merrors)\n\u001b[1;32m--> 854\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_execute_child(args, executable, preexec_fn, close_fds,\n\u001b[0;32m    855\u001b[0m                         pass_fds, cwd, env,\n\u001b[0;32m    856\u001b[0m                         startupinfo, creationflags, shell,\n\u001b[0;32m    857\u001b[0m                         p2cread, p2cwrite,\n\u001b[0;32m    858\u001b[0m                         c2pread, c2pwrite,\n\u001b[0;32m    859\u001b[0m                         errread, errwrite,\n\u001b[0;32m    860\u001b[0m                         restore_signals, start_new_session)\n\u001b[0;32m    861\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m    862\u001b[0m     \u001b[39m# Cleanup if the child failed starting.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\software\\lib\\subprocess.py:1307\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_start_new_session)\u001b[0m\n\u001b[0;32m   1306\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1307\u001b[0m     hp, ht, pid, tid \u001b[39m=\u001b[39m _winapi\u001b[39m.\u001b[39;49mCreateProcess(executable, args,\n\u001b[0;32m   1308\u001b[0m                              \u001b[39m# no special security\u001b[39;49;00m\n\u001b[0;32m   1309\u001b[0m                              \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m   1310\u001b[0m                              \u001b[39mint\u001b[39;49m(\u001b[39mnot\u001b[39;49;00m close_fds),\n\u001b[0;32m   1311\u001b[0m                              creationflags,\n\u001b[0;32m   1312\u001b[0m                              env,\n\u001b[0;32m   1313\u001b[0m                              cwd,\n\u001b[0;32m   1314\u001b[0m                              startupinfo)\n\u001b[0;32m   1315\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m   1316\u001b[0m     \u001b[39m# Child is launched. Close the parent's copy of those pipe\u001b[39;00m\n\u001b[0;32m   1317\u001b[0m     \u001b[39m# handles that only the child should have open.  You need\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1320\u001b[0m     \u001b[39m# pipe will not close when the child process exits and the\u001b[39;00m\n\u001b[0;32m   1321\u001b[0m     \u001b[39m# ReadFile will hang.\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] 系统找不到指定的文件。",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mExecutableNotFound\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32md:\\learnPytorch\\lesson4.ipynb Cell 11'\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/learnPytorch/lesson4.ipynb#X13sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m MyConvnetvis\u001b[39m.\u001b[39mformat \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpng\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/learnPytorch/lesson4.ipynb#X13sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m MyConvnetvis\u001b[39m.\u001b[39mdirectory \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m./\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/learnPytorch/lesson4.ipynb#X13sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m MyConvnetvis\u001b[39m.\u001b[39;49mview()\n",
      "File \u001b[1;32mc:\\software\\lib\\site-packages\\graphviz\\_tools.py:171\u001b[0m, in \u001b[0;36mdeprecate_positional_args.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    162\u001b[0m     wanted \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m=\u001b[39m\u001b[39m{\u001b[39;00mvalue\u001b[39m!r}\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[0;32m    163\u001b[0m                        \u001b[39mfor\u001b[39;00m name, value \u001b[39min\u001b[39;00m deprecated\u001b[39m.\u001b[39mitems())\n\u001b[0;32m    164\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mThe signature of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m will be reduced\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    165\u001b[0m                   \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m to \u001b[39m\u001b[39m{\u001b[39;00msupported_number\u001b[39m}\u001b[39;00m\u001b[39m positional args\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    166\u001b[0m                   \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlist\u001b[39m(supported)\u001b[39m}\u001b[39;00m\u001b[39m: pass \u001b[39m\u001b[39m{\u001b[39;00mwanted\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[0;32m    167\u001b[0m                   \u001b[39m'\u001b[39m\u001b[39m as keyword arg(s)\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m    168\u001b[0m                   stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[0;32m    169\u001b[0m                   category\u001b[39m=\u001b[39mcategory)\n\u001b[1;32m--> 171\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\software\\lib\\site-packages\\graphviz\\rendering.py:185\u001b[0m, in \u001b[0;36mRender.view\u001b[1;34m(self, filename, directory, cleanup, quiet, quiet_view)\u001b[0m\n\u001b[0;32m    150\u001b[0m \u001b[39m@_tools\u001b[39m\u001b[39m.\u001b[39mdeprecate_positional_args(supported_number\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[0;32m    151\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mview\u001b[39m(\u001b[39mself\u001b[39m,\n\u001b[0;32m    152\u001b[0m          filename: typing\u001b[39m.\u001b[39mUnion[os\u001b[39m.\u001b[39mPathLike, \u001b[39mstr\u001b[39m, \u001b[39mNone\u001b[39;00m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    155\u001b[0m          quiet: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    156\u001b[0m          quiet_view: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[0;32m    157\u001b[0m     \u001b[39m\"\"\"Save the source to file, open the rendered result in a viewer.\u001b[39;00m\n\u001b[0;32m    158\u001b[0m \n\u001b[0;32m    159\u001b[0m \u001b[39m    Convenience short-cut for running ``.render(view=True)``.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[39m        and no way to retrieve the application's exit status.\u001b[39;00m\n\u001b[0;32m    184\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 185\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrender(filename\u001b[39m=\u001b[39;49mfilename, directory\u001b[39m=\u001b[39;49mdirectory, view\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    186\u001b[0m                        cleanup\u001b[39m=\u001b[39;49mcleanup, quiet\u001b[39m=\u001b[39;49mquiet, quiet_view\u001b[39m=\u001b[39;49mquiet_view)\n",
      "File \u001b[1;32mc:\\software\\lib\\site-packages\\graphviz\\_tools.py:171\u001b[0m, in \u001b[0;36mdeprecate_positional_args.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    162\u001b[0m     wanted \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m=\u001b[39m\u001b[39m{\u001b[39;00mvalue\u001b[39m!r}\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[0;32m    163\u001b[0m                        \u001b[39mfor\u001b[39;00m name, value \u001b[39min\u001b[39;00m deprecated\u001b[39m.\u001b[39mitems())\n\u001b[0;32m    164\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mThe signature of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m will be reduced\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    165\u001b[0m                   \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m to \u001b[39m\u001b[39m{\u001b[39;00msupported_number\u001b[39m}\u001b[39;00m\u001b[39m positional args\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    166\u001b[0m                   \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlist\u001b[39m(supported)\u001b[39m}\u001b[39;00m\u001b[39m: pass \u001b[39m\u001b[39m{\u001b[39;00mwanted\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[0;32m    167\u001b[0m                   \u001b[39m'\u001b[39m\u001b[39m as keyword arg(s)\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m    168\u001b[0m                   stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[0;32m    169\u001b[0m                   category\u001b[39m=\u001b[39mcategory)\n\u001b[1;32m--> 171\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\software\\lib\\site-packages\\graphviz\\rendering.py:122\u001b[0m, in \u001b[0;36mRender.render\u001b[1;34m(self, filename, directory, view, cleanup, format, renderer, formatter, neato_no_op, quiet, quiet_view, outfile, engine, raise_if_result_exists, overwrite_source)\u001b[0m\n\u001b[0;32m    118\u001b[0m filepath \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave(filename, directory\u001b[39m=\u001b[39mdirectory, skip_existing\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)\n\u001b[0;32m    120\u001b[0m args\u001b[39m.\u001b[39mappend(filepath)\n\u001b[1;32m--> 122\u001b[0m rendered \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_render(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    124\u001b[0m \u001b[39mif\u001b[39;00m cleanup:\n\u001b[0;32m    125\u001b[0m     log\u001b[39m.\u001b[39mdebug(\u001b[39m'\u001b[39m\u001b[39mdelete \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m'\u001b[39m, filepath)\n",
      "File \u001b[1;32mc:\\software\\lib\\site-packages\\graphviz\\_tools.py:171\u001b[0m, in \u001b[0;36mdeprecate_positional_args.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    162\u001b[0m     wanted \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m=\u001b[39m\u001b[39m{\u001b[39;00mvalue\u001b[39m!r}\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[0;32m    163\u001b[0m                        \u001b[39mfor\u001b[39;00m name, value \u001b[39min\u001b[39;00m deprecated\u001b[39m.\u001b[39mitems())\n\u001b[0;32m    164\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mThe signature of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m will be reduced\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    165\u001b[0m                   \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m to \u001b[39m\u001b[39m{\u001b[39;00msupported_number\u001b[39m}\u001b[39;00m\u001b[39m positional args\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    166\u001b[0m                   \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlist\u001b[39m(supported)\u001b[39m}\u001b[39;00m\u001b[39m: pass \u001b[39m\u001b[39m{\u001b[39;00mwanted\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[0;32m    167\u001b[0m                   \u001b[39m'\u001b[39m\u001b[39m as keyword arg(s)\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m    168\u001b[0m                   stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[0;32m    169\u001b[0m                   category\u001b[39m=\u001b[39mcategory)\n\u001b[1;32m--> 171\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\software\\lib\\site-packages\\graphviz\\backend\\rendering.py:324\u001b[0m, in \u001b[0;36mrender\u001b[1;34m(engine, format, filepath, renderer, formatter, neato_no_op, quiet, outfile, raise_if_result_exists, overwrite_filepath)\u001b[0m\n\u001b[0;32m    320\u001b[0m     \u001b[39mraise\u001b[39;00m exceptions\u001b[39m.\u001b[39mFileExistsError(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39moutput file exists: \u001b[39m\u001b[39m{\u001b[39;00mos\u001b[39m.\u001b[39mfspath(outfile)\u001b[39m!r}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m    322\u001b[0m cmd \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m args\n\u001b[1;32m--> 324\u001b[0m execute\u001b[39m.\u001b[39;49mrun_check(cmd,\n\u001b[0;32m    325\u001b[0m                   cwd\u001b[39m=\u001b[39;49mfilepath\u001b[39m.\u001b[39;49mparent \u001b[39mif\u001b[39;49;00m filepath\u001b[39m.\u001b[39;49mparent\u001b[39m.\u001b[39;49mparts \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    326\u001b[0m                   quiet\u001b[39m=\u001b[39;49mquiet,\n\u001b[0;32m    327\u001b[0m                   capture_output\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m    329\u001b[0m \u001b[39mreturn\u001b[39;00m os\u001b[39m.\u001b[39mfspath(outfile)\n",
      "File \u001b[1;32mc:\\software\\lib\\site-packages\\graphviz\\backend\\execute.py:84\u001b[0m, in \u001b[0;36mrun_check\u001b[1;34m(cmd, input_lines, encoding, quiet, **kwargs)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     83\u001b[0m     \u001b[39mif\u001b[39;00m e\u001b[39m.\u001b[39merrno \u001b[39m==\u001b[39m errno\u001b[39m.\u001b[39mENOENT:\n\u001b[1;32m---> 84\u001b[0m         \u001b[39mraise\u001b[39;00m ExecutableNotFound(cmd) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[0;32m     85\u001b[0m     \u001b[39mraise\u001b[39;00m\n\u001b[0;32m     87\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m quiet \u001b[39mand\u001b[39;00m proc\u001b[39m.\u001b[39mstderr:\n",
      "\u001b[1;31mExecutableNotFound\u001b[0m: failed to execute WindowsPath('dot'), make sure the Graphviz executables are on your systems' PATH"
     ]
    }
   ],
   "source": [
    "from torchviz import make_dot\n",
    "x = torch.randn(1,1,28,28).requires_grad_(True)\n",
    "y = MyConvnet(x)\n",
    "MyConvnetvis = make_dot(y, params=dict(list(MyConvnet.named_parameters()) + [('x',x)]))\n",
    "MyConvnetvis.format = \"png\"\n",
    "MyConvnetvis.directory = \"./\"\n",
    "MyConvnetvis.view()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bfa0feef82d63fcbc8a3fe2fbb76c81f584951cc4bd84f2e5de3225fe1cd89e7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
